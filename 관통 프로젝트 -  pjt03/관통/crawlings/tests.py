import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

def crawl_toss_discussion(keyword):
    """
    í† ìŠ¤ì¦ê¶Œì—ì„œ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¢…ëª© í‚¤ì›Œë“œë¡œ ì¢…ëª©ì„ ê²€ìƒ‰í•˜ê³ ,
    ì²« ë²ˆì§¸ ì¢…ëª©ì˜ í† ë¡  íƒ­ì—ì„œ ëŒ“ê¸€ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•œ í›„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """

# í¬ë¡¬ ë“œë¼ì´ë²„ ì˜µì…˜ ì„¤ì •
options = webdriver.ChromeOptions()
options.add_argument("user-agent=Mozilla/5.0 ...")  # ì‚¬ìš©ì ì—ì´ì „íŠ¸ ì„¤ì •
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option("useAutomationExtension", False)
options.add_argument("disable-blink-features=AutomationControlled")

service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=options)

try:
    # 1. Toss ì¦ê¶Œ ì ‘ì†
    driver.get("https://tossinvest.com/")
    time.sleep(2)
    print("1ë‹¨ê³„ ì„±ê³µ")

    # ğŸ” 2. ë‹ë³´ê¸°(ê²€ìƒ‰ ë²„íŠ¼) í´ë¦­ â†’ ëª¨ë‹¬ ì—´ê¸°
    # search_button = WebDriverWait(driver, 10).until(
    #     EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[aria-label="ê²€ìƒ‰"]'))
    # )

    search_button = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-section-name="ê²€ìƒ‰"]'))
    )

    search_button.click()
    print("ğŸ” ê²€ìƒ‰ì°½ ì—´ê¸° ì„±ê³µ")

    # 3. ê²€ìƒ‰ input ì ‘ê·¼ ë° í‚¤ì›Œë“œ ì…ë ¥
    search_input = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, 'input._1x1gpvi6'))
    )
    search_input.clear()
    search_input.send_keys(keyword)
    print("2ë‹¨ê³„ ì„±ê³µ")
    time.sleep(2)


    # 3. ìë™ì™„ì„± ë¦¬ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ì¢…ëª© í´ë¦­
    first_result = WebDriverWait(driver, 10).until(
    EC.element_to_be_clickable((By.CSS_SELECTOR, 'button._1jnh59q0._1afau9j0[data-selected="true"]'))
    )
    first_result.click()
    print("3ë‹¨ê³„ ì„±ê³µ")

    # 4. ì»¤ë®¤ë‹ˆí‹° íƒ­ í´ë¦­
    discussion_tab = WebDriverWait(driver, 5).until(
        EC.element_to_be_clickable((By.XPATH, "//a[contains(text(), 'ì»¤ë®¤ë‹ˆí‹°')]"))
    )
    discussion_tab.click()
    time.sleep(3)

    # 5. í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
    soup = BeautifulSoup(driver.page_source, "html.parser")

    # 6. ëŒ“ê¸€ í¬ë¡¤ë§
    comments = soup.select("div.css-1v0mbdj")  # ì˜ˆì‹œ í´ë˜ìŠ¤, ì‹¤ì œ êµ¬ì¡° í™•ì¸ í•„ìš”
    results = []

    for c in comments:
        content = c.get_text().strip()
        if content:
            print("ëŒ“ê¸€:", content)
            results.append(content)

    # 7. ì €ì¥
    filename = f"{keyword}_discussion.txt"
    with open(filename, "w", encoding="utf-8") as f:
        for i, comment in enumerate(results, 1):
            f.write(f"{i}. {comment}\n")

    print(f"âœ… {len(results)}ê°œì˜ ëŒ“ê¸€ì„ {filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print("âŒ ì˜¤ë¥˜ ë°œìƒ:", e)

finally:
    driver.quit()
crawl_toss_discussion("ì‚¼ì„±ì „ì")