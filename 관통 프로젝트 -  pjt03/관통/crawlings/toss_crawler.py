import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager


def crawl_toss_discussion(keyword):
    """
    í† ìŠ¤ì¦ê¶Œì—ì„œ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¢…ëª© í‚¤ì›Œë“œë¡œ ì¢…ëª©ì„ ê²€ìƒ‰í•˜ê³ ,
    ì²« ë²ˆì§¸ ì¢…ëª©ì˜ í† ë¡  íƒ­ì—ì„œ ëŒ“ê¸€ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•œ í›„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    # í¬ë¡¬ ë“œë¼ì´ë²„ ì˜µì…˜ ì„¤ì •
    options = webdriver.ChromeOptions()
    options.add_argument("user-agent=Mozilla/5.0 ...")  # ì‚¬ìš©ì ì—ì´ì „íŠ¸ ì„¤ì •
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    options.add_argument("disable-blink-features=AutomationControlled")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    try:
        # 1. Toss ì¦ê¶Œ ì ‘ì†
        driver.get("https://tossinvest.com/")
        time.sleep(2)
        print("1ë‹¨ê³„ ì„±ê³µ")

        # 2. ë‹ë³´ê¸°(ê²€ìƒ‰ ë²„íŠ¼) í´ë¦­ â†’ ëª¨ë‹¬ ì—´ê¸°

        search_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-section-name="ê²€ìƒ‰"]'))
        )

        search_button.click()
        print("ğŸ” ê²€ìƒ‰ì°½ ì—´ê¸° ì„±ê³µ")

        # 2. ê²€ìƒ‰ input ì ‘ê·¼ ë° í‚¤ì›Œë“œ ì…ë ¥
        search_input = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'input._1x1gpvi6'))
        )
        search_input.clear()
        search_input.send_keys(keyword)
        print("2ë‹¨ê³„ ì„±ê³µ")
        time.sleep(2)


        # 3. ìë™ì™„ì„± ë¦¬ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ì¢…ëª© í´ë¦­
        first_result = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, 'button._1jnh59q0._1afau9j0[data-selected="true"]'))
        )
        first_result.click()
        print("3ë‹¨ê³„ ì„±ê³µ")

        # 4. ì»¤ë®¤ë‹ˆí‹° íƒ­ í´ë¦­
        community_tab = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, "//button[@role='tab' and span[text()='ì»¤ë®¤ë‹ˆí‹°']]"))
        )
        community_tab.click()
        print("4ë‹¨ê³„ ì„±ê³µ (ì»¤ë®¤ë‹ˆí‹° íƒ­ í´ë¦­ ì™„ë£Œ)")
        time.sleep(3)

        # 5. í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
        soup = BeautifulSoup(driver.page_source, "html.parser")

        info_div = soup.select_one("div._1sivumi0 > div:nth-of-type(1)")

        if info_div:
            spans = info_div.find_all("span")
            if len(spans) >= 2:
                company_name = spans[0].get_text(strip=True)
                stock_code = spans[1].get_text(strip=True)
                print("ì¢…ëª©ëª…:", company_name)
                print("ì¢…ëª©ì½”ë“œ:", stock_code)
            else:
                print("â— spanì´ ë¶€ì¡±í•©ë‹ˆë‹¤:", spans)
                company_name, stock_code = "ì •ë³´ ì—†ìŒ", "ì •ë³´ ì—†ìŒ"
        else:
            print("â— ì¢…ëª© ì •ë³´ divë¥¼ ëª» ì°¾ì•˜ì–´ìš”.")
            company_name, stock_code = "ì •ë³´ ì—†ìŒ", "ì •ë³´ ì—†ìŒ"

        # 6. ëŒ“ê¸€ í¬ë¡¤ë§
        comments = soup.select("article.comment span[class*='_60z0ev1']") 
        results = []

        for c in comments:
            content = c.get_text().strip()
            if content:
                print("ëŒ“ê¸€:", content)
                results.append(content)

        # 7. ì €ì¥
        filename = f"{keyword}_discussion.txt"
        with open(filename, "w", encoding="utf-8") as f:
            for i, comment in enumerate(results, 1):
                f.write(f"{i}. {comment}\n")

        print(f"âœ… {len(results)}ê°œì˜ ëŒ“ê¸€ì„ {filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        print(company_name)
        print(stock_code)

    except Exception as e:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", e)

    finally:
        driver.quit()

        return company_name, stock_code, results
