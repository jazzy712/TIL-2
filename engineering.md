## Prompt Engineering

- **토큰**
  
  - GPT와 같은 인공지능 모델에서 **텍스트 데이터를 처리하고 이해하는 기본 단위**
  
  - 토큰은 문장에서 단어로 생각할 수 있음
    
    - 각 토큰별로 고유한 숫자 할당
    
    - 영어보다 한글 문장을 표현하는데 더 많은 토큰 소요
      
      - 한글은 조합형 문자이기 때문
  
  - 최대 입력 토큰 제한
    
    - 각 LLM 모델마다 최대 입력 토큰 수 제한
  
  - 토큰 수 확인
    
    - openAI Docs tokenizer 페이지 활용

- OpenAI API 주요 파라미터
  
  - 필수 파라미터
    
    - **model** : GPT 모델 이름
    
    - **messages** : 대화 메시지 기록
  
  - 응답 다양성 제어
    
    - **temperature** : 다음 토큰(단어) 예측의 다양성 조정(0~2)
      
      - 응답의 **창의성**과 **다양성** 조정
      
      - 확률 분포를 날카롭거나 평탄하게 만드는 역할
      
      - 높은 확률은 더 높게, 낮은 확률은 더 낮게 조정
      
      - 모든 후보 단어의 확률을 조정하여 다양한 응답을 가능하게 함
      
      - 낮은 온도 : 높은 확률 요소가 더 강화되어 일관성 있는 응답 생성
      
      - 높은 온도 : 확률 분포가 평탄해져 다양한 요소가 선택될 가능성 증가
    
    - **top_p** : 선택 토큰의 확률 범위 제한(0~1)
      
      - 누적 확률 기반 응답 범위 제한
      
      - 확률 분포 범위(상위 확률 단어들만) 제한
      
      - 응답의 **신뢰성**과 **예측 가능성** 조정
      
      - 낮은 top_p : 특정 요소만 후보로 남음
      
      - 높은 top_p : 모든 요소를 후보로 포함
  
  - 낮은 temperature + 높은 top_p
    
    - 높은 확률 요소 집중(확률 분포 차이 강조)
    
    - 상위 확률 요소들을 다양하게 고려(누적 확률 범위 넓음)
      
      - 응답이 안정적이고 예측 고려
    
    - 기술 문서 작성, 고객 지원
  
  - 높은 temperature + 낮은 top_p
    
    - 다양한 요소 선택될 가능성 증가(확률 분포 평탄)
    
    - 선택 후보 제한적(누적 확률 범위 좁음)
      
      - 창의적이고 독창적 응답
      
      - 아이디어 도출, 소설 생성 

- 동작 흐름 요약
  
  - OpenAI 클라이언트를 초기화하고 API 키로 인증
  
  - 대화의 기본 지침(system)과 사용자 질문(user)을 **conversation_history**에 추가
  
  - OpenAI API에 **conversation_history**를 전달하여 **응답 생성**
  
  - 생성된 응답 출력
